{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, LSTM, GRU, Input\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.svm import SVR, LinearSVC, NuSVC, LinearSVR, NuSVR\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier, NearestCentroid, RadiusNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, GradientBoostingClassifier, \\\n",
    "     AdaBoostClassifier, RandomForestClassifier, AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier, LogisticRegressionCV, RidgeClassifier, ARDRegression, BayesianRidge, \\\n",
    "     ElasticNetCV, Lars, LarsCV, Lasso, LassoCV, LassoLars, LassoLarsCV, LassoLarsIC, OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV, \\\n",
    "     PassiveAggressiveRegressor, PoissonRegressor, RANSACRegressor, Ridge, RidgeCV, SGDRegressor, TheilSenRegressor, TweedieRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                  0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1                  0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2                  0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3                  0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4                  0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "...                ...     ...       ...        ...   ...     ...     ...   \n",
       "70687              1.0     0.0       1.0        1.0  37.0     0.0     0.0   \n",
       "70688              1.0     0.0       1.0        1.0  29.0     1.0     0.0   \n",
       "70689              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "70690              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "70691              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                       0.0           1.0     0.0  ...            1.0   \n",
       "1                       0.0           0.0     1.0  ...            1.0   \n",
       "2                       0.0           1.0     1.0  ...            1.0   \n",
       "3                       0.0           1.0     1.0  ...            1.0   \n",
       "4                       0.0           1.0     1.0  ...            1.0   \n",
       "...                     ...           ...     ...  ...            ...   \n",
       "70687                   0.0           0.0     0.0  ...            1.0   \n",
       "70688                   1.0           0.0     1.0  ...            1.0   \n",
       "70689                   1.0           0.0     1.0  ...            1.0   \n",
       "70690                   0.0           0.0     0.0  ...            1.0   \n",
       "70691                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "       NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0              0.0      3.0       5.0      30.0       0.0  1.0   4.0   \n",
       "1              0.0      3.0       0.0       0.0       0.0  1.0  12.0   \n",
       "2              0.0      1.0       0.0      10.0       0.0  1.0  13.0   \n",
       "3              0.0      3.0       0.0       3.0       0.0  1.0  11.0   \n",
       "4              0.0      2.0       0.0       0.0       0.0  0.0   8.0   \n",
       "...            ...      ...       ...       ...       ...  ...   ...   \n",
       "70687          0.0      4.0       0.0       0.0       0.0  0.0   6.0   \n",
       "70688          0.0      2.0       0.0       0.0       1.0  1.0  10.0   \n",
       "70689          0.0      5.0      15.0       0.0       1.0  0.0  13.0   \n",
       "70690          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "70691          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "       Education  Income  \n",
       "0            6.0     8.0  \n",
       "1            6.0     8.0  \n",
       "2            6.0     8.0  \n",
       "3            6.0     8.0  \n",
       "4            5.0     8.0  \n",
       "...          ...     ...  \n",
       "70687        4.0     1.0  \n",
       "70688        3.0     6.0  \n",
       "70689        6.0     4.0  \n",
       "70690        2.0     4.0  \n",
       "70691        6.0     2.0  \n",
       "\n",
       "[70692 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1 = pd.read_csv('..\\Dataset\\diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "data1 = pd.read_csv('..\\Dataset\\diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
    "# data1 = pd.read_csv('..\\Dataset\\diabetes_binary_health_indicators_BRFSS2015.csv')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = [column for column in data1.columns if data1[column].dtype != 'object']\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dtypes(data1):\n",
    "    for column in numerical_columns:\n",
    "        data1[column] = data1[column].astype('int8')\n",
    "    return data1\n",
    "\n",
    "data1 = set_dtypes(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of sample in whole dataset: 70692\n",
      "Total # of sample in train dataset: 49484\n",
      "Total # of sample in test dataset: 21208\n"
     ]
    }
   ],
   "source": [
    "X = data1.drop(columns='Diabetes_binary')\n",
    "Y = data1['Diabetes_binary']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(f'Total # of sample in whole dataset: {len(X)}')\n",
    "print(f'Total # of sample in train dataset: {len(X_train)}')\n",
    "print(f'Total # of sample in test dataset: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_Model():\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    dnn_model.add(Dense(32, activation='relu'))\n",
    "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
    "    dnn_model._name = 'DNN_Model'\n",
    "    return dnn_model\n",
    "\n",
    "def CNN_Model():\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(256, 3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Conv1D(64, 3, activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    # cnn_model.add(Conv1D(32, 3, activation='relu'))\n",
    "    # cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "    cnn_model._name = 'CNN_Model'\n",
    "    return cnn_model\n",
    "\n",
    "def LSTM_Model():\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=32, input_shape=(X_train.shape[1], 1)))\n",
    "    lstm_model.add(Dense(units=1))\n",
    "    lstm_model._name = 'LSTM_Model'\n",
    "    return lstm_model\n",
    "\n",
    "def GRU_Model():\n",
    "    gru_model = Sequential()\n",
    "    gru_model.add(GRU(units=32, input_shape=(X_train.shape[1], 1)))\n",
    "    gru_model.add(Dense(units=1))\n",
    "    gru_model._name = 'GRU_Model'\n",
    "    return gru_model\n",
    "\n",
    "def Autoencoder_Model():\n",
    "    # define the input shape and input layer\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    encoded_layer = Dense(256, activation='relu')(input_layer)\n",
    "    encoded_layer = Dense(64, activation='relu')(encoded_layer)\n",
    "    decoded_layer = Dense(16, activation='relu')(encoded_layer)\n",
    "    decoded_layer = Dense(input_shape[0], activation='sigmoid')(decoded_layer)\n",
    "\n",
    "    # define the Autoencoder model\n",
    "    autoencoder_model = Model(input_layer, decoded_layer)\n",
    "    autoencoder_model._name = 'Autoencoder_Model'\n",
    "\n",
    "    # compile the Autoencoder model and fit the Autoencoder model to the data\n",
    "    autoencoder_model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
    "    autoencoder_model.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test), verbose=2)\n",
    "    return autoencoder_model\n",
    "\n",
    "def NN_Algorithms():\n",
    "    nn_algorithms = [\n",
    "        # ('DNN', DNN_Model()),\n",
    "        ('CNN', CNN_Model()),\n",
    "        # ('LSTM', LSTM_Model()),\n",
    "        # ('GRU', GRU_Model()),\n",
    "        # ('Autoencoder', Autoencoder_Model())\n",
    "    ]\n",
    "    return nn_algorithms\n",
    "    \n",
    "def compile_train_model(model, X_train, y_train, X_test, y_test):\n",
    "    # model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n",
    "    return model \n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    acc = 'null'\n",
    "    y_pred  = model.predict(X_test)\n",
    "\n",
    "    if(model._name == 'Autoencoder_Model'):\n",
    "      r2  = round(r2_score(X_test, y_pred), 4)\n",
    "      mse = round(mean_squared_error(X_test, y_pred), 4)\n",
    "    else:\n",
    "      r2  = round(r2_score(y_test, y_pred), 4)\n",
    "      mse = round(mean_squared_error(y_test, y_pred), 4)\n",
    "    return acc, mse, r2\n",
    "\n",
    "def NN_result(result, name, acc, r2, mse):\n",
    "    result.append((name, acc, r2, mse))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 19, 256)           1024      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 9, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 7, 64)             49216     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 3, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,433\n",
      "Trainable params: 50,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "774/774 [==============================] - 3s 4ms/step - loss: 0.1834 - val_loss: 0.1788\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1769 - val_loss: 0.1757\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1753 - val_loss: 0.1745\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1750 - val_loss: 0.1742\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1747 - val_loss: 0.1742\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1744 - val_loss: 0.1758\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1742 - val_loss: 0.1748\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1744 - val_loss: 0.1750\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1740 - val_loss: 0.1743\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1738 - val_loss: 0.1741\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1739 - val_loss: 0.1763\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1736 - val_loss: 0.1732\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1736 - val_loss: 0.1736\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1737 - val_loss: 0.1743\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1735 - val_loss: 0.1738\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1732 - val_loss: 0.1739\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1733 - val_loss: 0.1727\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1732 - val_loss: 0.1739\n",
      "Epoch 19/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1731 - val_loss: 0.1742\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1731 - val_loss: 0.1742\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1729 - val_loss: 0.1728\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1730 - val_loss: 0.1744\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1729 - val_loss: 0.1739\n",
      "Epoch 24/100\n",
      "774/774 [==============================] - 3s 3ms/step - loss: 0.1730 - val_loss: 0.1731\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - 2s 3ms/step - loss: 0.1729 - val_loss: 0.1733\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - 3s 4ms/step - loss: 0.1728 - val_loss: 0.1738\n",
      "Epoch 27/100\n",
      "609/774 [======================>.......] - ETA: 0s - loss: 0.1727"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "\n",
    "algorithms = NN_Algorithms()\n",
    "\n",
    "for index, model in enumerate(algorithms):\n",
    "    print(model[0])\n",
    "    if(model[0] == 'Autoencoder'):\n",
    "        nn_model = model[1]\n",
    "    else:    \n",
    "        nn_model = compile_train_model(model[1], X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    acc, mse, r2= evaluate_model(nn_model, X_test, y_test)\n",
    "    result = NN_result(result, model[0], acc, r2, mse)\n",
    "    print('=' * 100)\n",
    "    \n",
    "nn_results_df = pd.DataFrame(result, columns=('Model Name', 'Accuracy', 'R-Square', 'MSE'))\n",
    "nn_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
